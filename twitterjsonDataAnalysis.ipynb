{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re,glob,warnings,json,operator,csv\n",
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "# nltk.download('stopwords') #Uncomment to download stopwords from Nltk\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisations\n",
    "words = []\n",
    "remove_list = ['rt','via','...']\n",
    "stop_words = []\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "data_records = 0\n",
    "created_records = 0\n",
    "deleted_records = 0\n",
    "ts = []\n",
    "hashtags = []\n",
    "hashtag_count = []\n",
    "users = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r, d, f in os.walk(os.getcwd()):\n",
    "    for file in f:\n",
    "        if '.json' in file:\n",
    "            os.path.join(os.path.abspath(r), file)\n",
    "            with open(os.path.join(r, file),'r') as fp:\n",
    "                data = fp.readlines()\n",
    "                fp.close()\n",
    "            data_records += len(data)\n",
    "            for line in data: \n",
    "                #Converting all text to lowercase\n",
    "                tweets = json.loads(line.lower())\n",
    "                if (\"created_at\" in tweets):\n",
    "                    created_records += 1\n",
    "                    #Tokenising tweets\n",
    "                    words += TweetTokenizer().tokenize(tweets['text'])\n",
    "                    ts.append(tweets['created_at'])\n",
    "                    hashtag_count.append(len(tweets['entities']['hashtags']))\n",
    "                    for user in  tweets['entities']['user_mentions']:\n",
    "                        users.append(user['screen_name'])\n",
    "                elif(\"delete\" in tweets):\n",
    "                    deleted_records += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all stopwords,purely numeric and characters 'rt','via','...'                    \n",
    "words = [a for a in words if ((not a.isnumeric()) and (a not in remove_list) and (a not in stop_words))]\n",
    "common_words = []\n",
    "common_words = [a for a in words if re.sub(\"[^A-Za-z0-9]\",\"\",a) != \"\"]\n",
    "common_words_30 = Counter(common_words).most_common(30)\n",
    "common_hashtag_count = Counter(hashtag_count).most_common(len(hashtag_count))\n",
    "common_users_30 = Counter(users).most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "common_words_30_table = PrettyTable()\n",
    "common_words_30_table.field_names = [\"Words\",\"Frequency/count\"]\n",
    "for entry in common_words_30:\n",
    "    common_words_30_table.add_row(list(entry))\n",
    "    \n",
    "common_hashtag_count_table = PrettyTable()\n",
    "common_hashtag_count_table.field_names = [\"No of Hashtags in a Tweet\",\"Frequency/count\"]\n",
    "for entry in common_hashtag_count:\n",
    "    common_hashtag_count_table.add_row(list(entry))\n",
    "\n",
    "common_users_table = PrettyTable()\n",
    "common_users_table.field_names = [\"User\",\"Frequency/count\"]\n",
    "for entry in common_users_30:\n",
    "    common_users_table.add_row(list(entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records is:  4928218\n",
      "Total Created tweets is:  3585053\n",
      "Total Deleted tweets is:  1343164\n",
      "Earliest Created tweet is:  mon sep 30 06:29:00 +0000 2019\n",
      "Latest Created tweet is:  tue oct 01 05:59:59 +0000 2019\n"
     ]
    }
   ],
   "source": [
    "ts = list(set(ts))\n",
    "ts.sort()\n",
    "print('Total records is: ',data_records)\n",
    "print('Total Created tweets is: ',created_records)\n",
    "print('Total Deleted tweets is: ',deleted_records)\n",
    "print('Earliest Created tweet is: ',ts[0])\n",
    "print('Latest Created tweet is: ',ts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Frequency Distribution table for  30 most commonly used words in a tweet is: \n",
      " +--------+-----------------+\n",
      "| Words  | Frequency/count |\n",
      "+--------+-----------------+\n",
      "|   de   |      283316     |\n",
      "|  que   |      208604     |\n",
      "|   la   |      139568     |\n",
      "|   en   |      93443      |\n",
      "|   el   |      91867      |\n",
      "|   e    |      68260      |\n",
      "|   se   |      65471      |\n",
      "|   eu   |      61208      |\n",
      "|  like  |      56923      |\n",
      "|   un   |      54848      |\n",
      "|  por   |      47898      |\n",
      "|   es   |      45188      |\n",
      "|  para  |      44260      |\n",
      "|  los   |      42176      |\n",
      "|  one   |      41569      |\n",
      "|   na   |      39741      |\n",
      "|  n√£o   |      38125      |\n",
      "|   te   |      37363      |\n",
      "|  con   |      36009      |\n",
      "|   lo   |      34770      |\n",
      "|  get   |      34536      |\n",
      "|  love  |      33356      |\n",
      "|   le   |      32601      |\n",
      "|   da   |      32150      |\n",
      "|   si   |      31520      |\n",
      "|   q    |      31285      |\n",
      "|  time  |      30437      |\n",
      "| people |      30087      |\n",
      "|  del   |      29887      |\n",
      "|  know  |      29166      |\n",
      "+--------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "print('The Frequency Distribution table for  30 most commonly used words in a tweet is: \\n',common_words_30_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Frequency Distribution table for Hashtags in a tweet is: \n",
      " +---------------------------+-----------------+\n",
      "| No of Hashtags in a Tweet | Frequency/count |\n",
      "+---------------------------+-----------------+\n",
      "|             0             |     3091187     |\n",
      "|             1             |      255473     |\n",
      "|             2             |      105684     |\n",
      "|             3             |      55786      |\n",
      "|             4             |      32137      |\n",
      "|             5             |      17976      |\n",
      "|             6             |      10557      |\n",
      "|             7             |       7851      |\n",
      "|             8             |       3326      |\n",
      "|             9             |       2103      |\n",
      "|             10            |       1129      |\n",
      "|             11            |       744       |\n",
      "|             12            |       497       |\n",
      "|             13            |       254       |\n",
      "|             14            |       112       |\n",
      "|             15            |        72       |\n",
      "|             16            |        64       |\n",
      "|             17            |        37       |\n",
      "|             18            |        17       |\n",
      "|             20            |        13       |\n",
      "|             19            |        12       |\n",
      "|             24            |        7        |\n",
      "|             21            |        7        |\n",
      "|             23            |        4        |\n",
      "|             22            |        2        |\n",
      "|             28            |        1        |\n",
      "|             25            |        1        |\n",
      "+---------------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "print('The Frequency Distribution table for Hashtags in a tweet is: \\n',common_hashtag_count_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Frequency Distribution table for  30 most commonly mentioned users in a tweet is: \n",
      " +-----------------+-----------------+\n",
      "|       User      | Frequency/count |\n",
      "+-----------------+-----------------+\n",
      "|     bts_twt     |      24359      |\n",
      "| realdonaldtrump |      20047      |\n",
      "|   weareoneexo   |       6403      |\n",
      "|    bts_bighit   |       4485      |\n",
      "|     youtube     |       4138      |\n",
      "|      superm     |       2744      |\n",
      "|  b_hundred_hyun |       2484      |\n",
      "| stranger_things |       2261      |\n",
      "|      m78akh     |       2064      |\n",
      "|  charliekirk11  |       1868      |\n",
      "|  hillaryclinton |       1819      |\n",
      "|   narendramodi  |       1806      |\n",
      "|   rudygiuliani  |       1780      |\n",
      "|    rterdogan    |       1701      |\n",
      "|     bambam1a    |       1661      |\n",
      "|  turnupgvngstar |       1624      |\n",
      "|    pledis_17    |       1580      |\n",
      "|   got7official  |       1490      |\n",
      "|  repadamschiff  |       1463      |\n",
      "|  nicolasmaduro  |       1386      |\n",
      "|  knockknock0408 |       1359      |\n",
      "|       aoc       |       1331      |\n",
      "|     almosahf    |       1327      |\n",
      "|   rmapalacios   |       1289      |\n",
      "|  speakerpelosi  |       1288      |\n",
      "|   kamalaharris  |       1286      |\n",
      "|     h0egenic    |       1275      |\n",
      "|    iambeckyg    |       1237      |\n",
      "|   sethabramson  |       1206      |\n",
      "|  vijaysethuoffl |       1196      |\n",
      "+-----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "print('The Frequency Distribution table for  30 most commonly mentioned users in a tweet is: \\n',common_users_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_1000 = Counter(common_words).most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_1000 = {}\n",
    "for w in common_words_1000:\n",
    "        words_1000[w[0]] = w[1]\n",
    "sorted_words = dict(sorted(words_1000.items(), key=operator.itemgetter(1),reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "final_words_1000 = {}\n",
    "for k,v in sorted_words.items():\n",
    "       values.append(v)\n",
    "for i,v in enumerate(values):\n",
    "     final_words_1000[i+1] = v\n",
    "with open('final_words_1000.csv', 'w',encoding='utf-8') as f:\n",
    "    for key in final_words_1000.keys():\n",
    "        f.write(\"%s,%s\\n\"%(key,final_words_1000[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_30_list = [word[0] for word in common_words_30]\n",
    "words_re = re.compile(\"|\".join(common_words_30_list))\n",
    "common_word_tweet_date = []\n",
    "for r, d, f in os.walk(os.getcwd()):\n",
    "    for file in f:\n",
    "        if '.json' in file:\n",
    "            os.path.join(os.path.abspath(r), file)\n",
    "            with open(os.path.join(r, file),'r') as fp:\n",
    "                data = fp.readlines()\n",
    "                fp.close()\n",
    "            data_records += len(data)\n",
    "            for line in data: \n",
    "                #Converting all text to lowercase\n",
    "                tweets = json.loads(line.lower())\n",
    "                if (\"created_at\" in tweets):\n",
    "                    if (words_re.search(tweets['text'])):\n",
    "                        common_word_tweet_date.append(tweets['created_at'][:16] + \":00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final.csv', 'w',encoding='utf-8') as f:\n",
    "    for key,value in dict(Counter(common_word_tweet_date)).items():\n",
    "        f.write(\"%s,%s\\n\"%(key,value))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
